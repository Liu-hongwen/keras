{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv(\"data_small.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context</th>\n",
       "      <th>tag</th>\n",
       "      <th>words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>读者故事：“婆婆陪睡，我成了保姆”   \"  茫茫人海中，为防大家走失，请大家   点击上方...</td>\n",
       "      <td>0</td>\n",
       "      <td>读者 故事 婆婆 陪 睡 我成 保姆 茫茫人海 中 为防 走失 请 点击 上方 婆媳关系 婚...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>剖宫产期间产妇低体温的预测因素    背景与目的   虽然围术期低体温可增加产妇发病率，但少...</td>\n",
       "      <td>1</td>\n",
       "      <td>剖宫产 期间 产妇 低 体温 预测 因素 背景 目的 围术期 低 体温 增加 产妇 发病率 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>挨过这波雨雪和降温，温暖和阳光就在前方！还要熬几天？ 这几天出门的小伙伴  抬头望天  都要...</td>\n",
       "      <td>1</td>\n",
       "      <td>挨过 这波 雨雪 降温 温暖 阳光 前方 熬 几天 几天 出门 小伙伴 抬头 望天 叹一口气...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>杨立新：我不喝豆汁，太馊了！陈佩斯回答7个字让网友坐不住了！ 杨立新：我不喝豆汁，太馊了！陈...</td>\n",
       "      <td>1</td>\n",
       "      <td>杨立新 喝 豆汁 太 馊 陈佩斯 回答 字 网友 坐不住 杨立新 喝 豆汁 太 馊 陈佩斯 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>上汽大众2018年销量继续领跑国内乘用车市场，背后的实力值得深究  2018年的车市格外严峻...</td>\n",
       "      <td>1</td>\n",
       "      <td>上汽 大众 2018 年销量 领跑 国内 乘用车 市场 背后 实力 值得 深究 2018 车...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             context  tag  \\\n",
       "0  读者故事：“婆婆陪睡，我成了保姆”   \"  茫茫人海中，为防大家走失，请大家   点击上方...    0   \n",
       "1  剖宫产期间产妇低体温的预测因素    背景与目的   虽然围术期低体温可增加产妇发病率，但少...    1   \n",
       "2  挨过这波雨雪和降温，温暖和阳光就在前方！还要熬几天？ 这几天出门的小伙伴  抬头望天  都要...    1   \n",
       "3  杨立新：我不喝豆汁，太馊了！陈佩斯回答7个字让网友坐不住了！ 杨立新：我不喝豆汁，太馊了！陈...    1   \n",
       "4  上汽大众2018年销量继续领跑国内乘用车市场，背后的实力值得深究  2018年的车市格外严峻...    1   \n",
       "\n",
       "                                               words  \n",
       "0  读者 故事 婆婆 陪 睡 我成 保姆 茫茫人海 中 为防 走失 请 点击 上方 婆媳关系 婚...  \n",
       "1  剖宫产 期间 产妇 低 体温 预测 因素 背景 目的 围术期 低 体温 增加 产妇 发病率 ...  \n",
       "2  挨过 这波 雨雪 降温 温暖 阳光 前方 熬 几天 几天 出门 小伙伴 抬头 望天 叹一口气...  \n",
       "3  杨立新 喝 豆汁 太 馊 陈佩斯 回答 字 网友 坐不住 杨立新 喝 豆汁 太 馊 陈佩斯 ...  \n",
       "4  上汽 大众 2018 年销量 领跑 国内 乘用车 市场 背后 实力 值得 深究 2018 车...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = []\n",
    "with open('stopwords.txt', \"r\", encoding='utf-8') as f:\n",
    "    line = f.readline()\n",
    "    while line:\n",
    "        stopwords.append(line[:-1])\n",
    "        line = f.readline()\n",
    "stopwords = set(stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /tmp/jieba.cache\n",
      "Loading model cost 0.805 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    }
   ],
   "source": [
    "import jieba\n",
    "document = []    \n",
    "for i in range(len(data['context'])):\n",
    "    seg_list = list(jieba.cut(data['context'][i]))\n",
    "    sentence = [w for w in seg_list if w not in stopwords]\n",
    "    sentence = \" \".join(sentence)\n",
    "    document.append(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(454, 32119)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "count_vec = CountVectorizer()\n",
    "X = count_vec.fit_transform(document)\n",
    "print(X.shape)\n",
    "# print(X)\n",
    "# print(count_vec.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(454, 32119)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf_model = TfidfVectorizer(max_df=0.6)\n",
    "X = tfidf_model.fit_transform(document)\n",
    "print(X.shape)\n",
    "# print(X)\n",
    "# print(tfidf_model.vocabulary_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 统计高频词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140867\n"
     ]
    }
   ],
   "source": [
    "import jieba\n",
    "words = []    \n",
    "for i in range(len(data['context'])):\n",
    "    seg_list = list(jieba.cut(data['context'][i]))\n",
    "    word = [w for w in seg_list if w not in stopwords]\n",
    "    words.extend(word)\n",
    "\n",
    "print(len(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_frequency = {}\n",
    "for word in words:\n",
    "    word_frequency[word] = word_frequency.get(word, 0) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(word_frequency) # 字典\n",
    "# print(word_frequency.items()) # 以列表返回可遍历的(键, 值)元组数组"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_frequency_sorted = sorted(word_frequency.items(), key=lambda x: x[1], reverse=True) # reverse=True 降序 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('中', 626),\n",
       " ('中国', 542),\n",
       " ('说', 432),\n",
       " ('工作', 378),\n",
       " ('文化', 341),\n",
       " ('海洋', 295),\n",
       " ('做', 287),\n",
       " ('发展', 280),\n",
       " ('2019', 266),\n",
       " ('新', 265)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_frequency_sorted[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
